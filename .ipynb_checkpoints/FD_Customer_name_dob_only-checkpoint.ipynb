{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import tensorflow as t\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data from the dataset\n",
    "df=pd.read_csv('Customers_File.csv', delimiter=',')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Pre-processing\n",
    "#Removal of extra spaces from the data\n",
    "df['First_Name']=df['First_Name'].str.lower()\n",
    "df['Last_Name']=df['Last_Name'].str.lower()\n",
    "#Converting columns into Lists for the tokernizer\n",
    "first_name=list(df.First_Name.values)\n",
    "last_name=list(df.Last_Name.values)\n",
    "fraud=list(df.Fraud.values)\n",
    "\n",
    "#DOB to be split into DD MM and YYYY for ML algo\n",
    "df[['DD','MM','YYYY']]=df.DOB.str.split(\"-\", expand=True,)\n",
    "#Now DOB column can be dropped from the dataframe\n",
    "df=df.drop(columns=['DOB','Date_of_joining','Date_of_exit'])\n",
    "df['DD']=df['DD'].astype(int)\n",
    "df['MM']=df['MM'].astype(int)\n",
    "df['YYYY']=df['YYYY'].astype(int)\n",
    "\n",
    "fraud={\n",
    "    'Fraud' : 1,\n",
    "    'Not Fraud' : 0\n",
    "}\n",
    "\n",
    "df = df.replace({'Fraud': fraud})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing First Name\n",
    "tk_fn = Tokenizer(num_words=2, lower=False, oov_token=None)\n",
    "tk_fn.fit_on_texts(first_name)\n",
    "wi_fn=tk_fn.word_index\n",
    "wi_fn\n",
    "\n",
    "#Tokenizing Last Name\n",
    "tk_ln = Tokenizer(num_words=2, lower=False, oov_token=None)\n",
    "tk_ln.fit_on_texts(last_name)\n",
    "wi_ln=tk_ln.word_index\n",
    "wi_ln\n",
    "\n",
    "#Reflecting changes to the Dataframe\n",
    "df=df.replace({\"First_Name\" : wi_fn})\n",
    "df=df.replace({\"Last_Name\" : wi_ln})\n",
    "\n",
    "df = df.drop(columns='Customer_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling of the data in the dataframe to avoid overfitting or underfitting\n",
    "df = df.sample(frac = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning Starts\n",
    "#Imports\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from matplotlib import gridspec\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing data into Input Vector and Dependent Variable\n",
    "X=df[['First_Name','Last_Name','DD','MM','YYYY']].values\n",
    "y=df['Fraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corelation Matrix\n",
    "corrmat=df.corr()\n",
    "fig = plt.figure(figsize = (12, 9)) \n",
    "sns.heatmap(corrmat, vmax = .8, square = True) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "print('Train set:', X_train.shape, y_train.shape)\n",
    "print('Test set:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "FDTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "FDTree # it shows the default parameters\n",
    "FDTree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "predTree = FDTree.predict(X_test)\n",
    "print (predTree [0:5])\n",
    "print (y_test [0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "# Evaluating the classifier \n",
    "# printing every score of the classifier \n",
    "# scoring in anything \n",
    "from sklearn.metrics import classification_report, accuracy_score  \n",
    "from sklearn.metrics import precision_score, recall_score \n",
    "from sklearn.metrics import f1_score, matthews_corrcoef \n",
    "from sklearn.metrics import confusion_matrix \n",
    "  \n",
    "print(\"The model used is Decision Tree classifier\") \n",
    "  \n",
    "acc = accuracy_score(y_test, predTree) \n",
    "print(\"The accuracy is {}\".format(acc)) \n",
    "  \n",
    "#prec = precision_score(y_test, predTree) \n",
    "#print(\"The precision is {}\".format(prec)) \n",
    "  \n",
    "rec = recall_score(y_test, predTree) \n",
    "print(\"The recall is {}\".format(rec)) \n",
    "  \n",
    "f1 = f1_score(y_test, predTree) \n",
    "print(\"The F1-Score is {}\".format(f1)) \n",
    "  \n",
    "MCC = matthews_corrcoef(y_test, predTree) \n",
    "print(\"The Matthews correlation coefficient is{}\".format(MCC)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the confusion matrix \n",
    "LABELS = ['Normal', 'Fraud'] \n",
    "conf_matrix = confusion_matrix(y_test, predTree) \n",
    "plt.figure(figsize =(12, 12)) \n",
    "sns.heatmap(conf_matrix, xticklabels = LABELS,  \n",
    "            yticklabels = LABELS, annot = True, fmt =\"d\"); \n",
    "plt.title(\"Confusion matrix\") \n",
    "plt.ylabel('True class') \n",
    "plt.xlabel('Predicted class') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(FDTree,'./FDTree.joblib', compress=True)\n",
    "joblib.dump(wi_fn,'./wi_fn.joblib', compress=True)\n",
    "joblib.dump(wi_ln,'./wi_ln.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
