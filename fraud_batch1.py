#Customer Fraud Detection WebApp File Upload

import pandas as pd
import joblib
import os
import streamlit as st
import datetime
from nltk.tokenize.treebank import TreebankWordDetokenizer as wd
import seaborn as sns
import base64
from pathlib import Path
import matplotlib.pyplot as plt

def img_to_bytes(img_path):
    img_bytes = Path(img_path).read_bytes()
    encoded = base64.b64encode(img_bytes).decode()
    return encoded

header_html = "<img src='data:image/png;base64,{}' class='img-fluid' width='300' height='240'>".format(
    img_to_bytes("CG_Invent.PNG")
)
st.markdown(
    header_html, unsafe_allow_html=True,
)

sidebar_html = "<img src='data:image/png;base64,{}' class='img-fluid' width='200' height='160'>".format(
    img_to_bytes("DRR.PNG")
)
st.sidebar.markdown(
    sidebar_html, unsafe_allow_html=True,
)

#Title
st.subheader("Customer Fraud Detection")
st.markdown("Please upload a <a style='color:red'>.csv</a> file containing the customer alerts generated by the AML application. The Artificial Intelligence model would identify the False Positive alerts from the input data.", unsafe_allow_html=True)

st.sidebar.title("Lookup data")
st.set_option('deprecation.showfileUploaderEncoding', False)

#Get User Inputs
def get_user_input():
    
    uploaded_file = st.file_uploader("Choose a CSV file for processing", type='csv')
    if uploaded_file is not None:
        data = pd.read_csv(uploaded_file)
    else:
        st.stop()        
    return data

user_input = get_user_input()

#Display User Input
st.subheader('User Input:')
if st.checkbox('Show User Input'):
    st.write(user_input)

#Load machine learning models
path_to_artifacts = os.path.normpath(os.getcwd())
#model = joblib.load(path_to_artifacts + "\FDTree.joblib")
#wi_fn = joblib.load(path_to_artifacts + "\wi_fn.joblib")
#wi_ln = joblib.load(path_to_artifacts + "\wi_ln.joblib")
#To try to fix it in heroku
model = joblib.load(path_to_artifacts + "/FDTree.joblib")
wi_fn = joblib.load(path_to_artifacts + "/wi_fn.joblib")
wi_ln = joblib.load(path_to_artifacts + "/wi_ln.joblib")

#Identify New Customers
def new_customer_identification(input_data):
    fname_model_list = list(wi_fn.keys())
    lname_model_list = list(wi_ln.keys())
    input_data["First_Name"] = input_data["First_Name"].str.lower()
    input_data["Last_Name"] = input_data["Last_Name"].str.lower()
    input_data['Dedup'] = input_data.First_Name.isin(fname_model_list).astype(int)
    input_data['Dedup'] = input_data.Last_Name.isin(lname_model_list).astype(int)

    return input_data   

#Data Pre processing
def preprocessing(input_data):
    #input_data["First_Name"] = input_data["First_Name"].str.lower()
    #input_data["Last_Name"] = input_data["Last_Name"].str.lower()
    #DOB to be split into DD MM and YYYY for ML algo
    input_data[['DD','MM','YYYY']]=input_data.DOB.str.split("-", expand=True,)
    input_data['DD']=input_data['DD'].astype(int)
    input_data['MM']=input_data['MM'].astype(int)
    input_data['YYYY']=input_data['YYYY'].astype(int)
    #Now DOB column can be dropped from the dataframe
    input_data=input_data.drop(columns=['DOB','Customer_Type', 'PAN', 'Deceased_Flag', 'Gender', 'Martial_Status', 'PEP_Flag', 'CTF_Flag', 'Country_of_residence', 'Country_of_Origin'])

    input_data = new_customer_identification(input_data)

    try:       
        input_data = input_data.replace({"First_Name" : wi_fn})
        input_data = input_data.replace({"Last_Name" : wi_ln})
        #st.write("Names replaced")
    except Exception:
        return {"status": "Error", "message": "Error in conversion"}
    
    #cols = list(input_data.columns)
    #cols = [cols[-1]] + cols[:-1]
    #input_data=input_data[cols]
    #st.write(input_data)

    return input_data

#user_input_pr=preprocessing(user_input)
def predict(input_data):
    return model.predict_proba(input_data)
        
def postprocessing(input_data):
    if input_data[1] == 0:
        label = 'False Positive'
    else :
        label = 'Fraud'
    return {"probability": input_data[1], "label": label, "status": "OK"}
        
def compute_prediction(input_data):
    actual_data = input_data
    input_data = preprocessing(input_data)
    pred_full={}
    for i in input_data.index:
        #st.write(predict(input_data[i:i+1]))
        if input_data.at[i,'Dedup'] == 1:
            prediction = predict(input_data.iloc[i:i+1, :-1])[0]  # for the complete file
            #st.write("Prediction is", prediction)
            prediction = postprocessing(prediction)
            #st.write("Prediction post processing is", prediction)
            pred_full.update({ i : prediction['label']})
        else :
            label = 'New Customer'
            prediction= {"probability": 2, "label": label, "status": "OK"}
            pred_full.update({ i : prediction['label']})

    #st.write("Final Dict", pred_full)    
    df_pred=pd.DataFrame(list(pred_full.items()), columns=['id','label'])            
    df_pred.drop(columns='id')
    #st.write("Latest Prediction post processing is", df_pred)        
    output_data = pd.concat([input_data, df_pred.reindex(input_data.index)], axis=1)
    output_data['First_Name']=actual_data['First_Name']
    output_data['Last_Name']=actual_data['Last_Name']
    #output_data = output_data.drop(columns='Dedup')

    return output_data

#Prediction
import matplotlib.patches as mpatches
prediction=compute_prediction(user_input)


#plt.style.use('ggplot')
#fig = plt.figure(figsize=(6,2))
#ax = fig.add_axes([0,0,1,1])
vals=prediction.groupby('label')['First_Name'].nunique()
vals_series=vals.rename('Classification')
#vals=vals.to_dict()
#x= vals.keys()
#y= vals.values()
#plt.title('Number of False Positives Captured')
#plt.xlabel('Classification')
#plt.ylabel('Count')
#ax.bar(x,y)
#st.set_option('deprecation.showPyplotGlobalUse', False)


#False Positive Percentage Calculation
#vals_series.re_index()
#fp_df=pd.DataFrame.from_dict(vals)
st.write(vals_series)

tot_count = vals_series.sum()
fp_count = vals_series.iloc[0:1].sum()
fp_percent= (fp_count/tot_count)*100
st.write("False positive percentage reduced", fp_percent)
#st.markdown('<h2>False positive percentage reduced  fp_percent </h2>', unsafe_allow_html=True)
#st.pyplot()
st.bar_chart(vals_series.to_frame(), width=400,use_container_width=False)
st.text("Note : Hover over the plotted bar")
st.subheader('Classification:')
if st.checkbox('Show Classification'):
    st.table(prediction[['First_Name', 'Last_Name' ,'label']])

def get_table_download_link(df):
    """Generates a link allowing the data in a given panda dataframe to be downloaded
    in:  dataframe
    out: href string
    """
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()  # some strings <-> bytes conversions necessary here
    href = f'<a href="data:file/csv;base64,{b64}">Download csv file</a>'
    return href

st.markdown(get_table_download_link(prediction[['First_Name', 'Last_Name' ,'label']]), unsafe_allow_html=True)

#Lookup Single User Data

def get_lookup_input():
    first_name = st.sidebar.text_input("First Name", "SAED")
    last_name = st.sidebar.text_input("Last Name", "ELHOORIE")
    dob = st.sidebar.date_input("Date of Birth")
    dob= dob.strftime("%d-%m-%Y")
    #Store data in a dictionary
    user_data = {
        'First_Name': first_name,
        'Last_Name': last_name,
        'DOB':dob
    }
    
    #Transform data into dataframe
    features = pd.DataFrame(user_data, index=[0])
    return features

lookup_input = get_lookup_input()

#Data Pre processing
def lookup_preprocessing(input_data):
    # JSON to pandas DataFrame
    input_data = pd.DataFrame(input_data, index=[0])
    input_data["First_Name"] = input_data["First_Name"].str.lower()
    input_data["Last_Name"] = input_data["Last_Name"].str.lower()       
    input_data = input_data.replace({"First_Name" : wi_fn})
    input_data = input_data.replace({"Last_Name" : wi_ln})
        
    #DOB to be split into DD MM and YYYY for ML algo
    input_data[['DD','MM','YYYY']]=input_data.DOB.str.split("-", expand=True,)
    #Now DOB column can be dropped from the dataframe
    input_data=input_data.drop(columns='DOB')
    input_data['DD']=input_data['DD'].astype(int)
    input_data['MM']=input_data['MM'].astype(int)
    input_data['YYYY']=input_data['YYYY'].astype(int)
        
    return input_data

#user_input_pr=preprocessing(user_input)
def lookup_predict(input_data):
    return model.predict_proba(input_data)
        
def lookup_postprocessing(input_data):
    if input_data[1] == 1:
        label = 'Fraud'
    else :
        label = 'Not Fraud'
    return {"probability": input_data[1], "label": label, "status": "OK"}
        
def lookup_compute_prediction(input_data):
    try:
        input_data = lookup_preprocessing(input_data)
        #st.write(input_data)
        prediction = lookup_predict(input_data)[0]  # only one sample
        prediction = lookup_postprocessing(prediction)
    except Exception as e:
        return {"status": "Error", "message": str(e)}

    return prediction

#Predcition
lookup_prediction=lookup_compute_prediction(lookup_input)
st.sidebar.subheader('Classification:')
st.sidebar.write(lookup_prediction['label'])

#About the dataset
st.subheader("About the dataset")
st.markdown("The dataset used to produce the above output is a customer dataset. A machine learning decision tree model has been trained to predict the Fradulent customers. This model would help reduce the false positive alerts generated by the AML applications.")
#Corelation matrix
from PIL import Image
image = Image.open('Confmat.png')
st.image(image, use_column_width=True)